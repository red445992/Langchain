{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd8dd12-e347-4878-a222-d38631051fd6",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc744c-7149-417b-b08e-abd3d5c1e1ca",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f96c19-9578-4130-b9cb-9d851be4ddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma3:1b http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import requests\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_= load_dotenv(find_dotenv())\n",
    "\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\")\n",
    "OLLAMA_API_URL = os.getenv(\"OLLAMA_API_URL\")\n",
    "\n",
    "print(OLLAMA_MODEL,OLLAMA_API_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07edfdd2-4600-492c-aff6-affefa7abf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt,model=OLLAMA_MODEL,temperature=0):\n",
    "    \"\"\"\n",
    "    Generates reponses from ollama LLM\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_API_URL}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\":model,\n",
    "        \"prompt\":prompt,\n",
    "        \"temperature\":temperature,\n",
    "        \"stream\":False,\n",
    "    }\n",
    "    response = requests.post(url,json=payload)\n",
    "    if response.status_code!=200:\n",
    "        raise Exception(f\"Ollama API error : {response.status_code} {response.text}\")\n",
    "    data = response.json()\n",
    "    return data['response']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d8155f-b38a-4aab-bc40-80677fb93eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ebfb97f-fbb3-4303-b232-b518bf1fb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"gemma3:1b\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d80498-fd24-46d6-8b52-bcc65745bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14520\\1082414350.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14520\\1082414350.py:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91084d7e-8353-4b89-9706-f887400e15b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Aditya\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Aditya! Itâ€™s lovely to meet you. Iâ€™m glad youâ€™re here. ðŸ˜Š \\n\\nTo help me understand a little better, could you tell me what youâ€™d like to do today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Aditya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "699abb12-1ae9-424f-ac9b-ba60b3775b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Aditya\n",
      "AI: Hello Aditya! Itâ€™s lovely to meet you. Iâ€™m glad youâ€™re here. ðŸ˜Š \n",
      "\n",
      "To help me understand a little better, could you tell me what youâ€™d like to do today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, thatâ€™s a fundamental question! 1 + 1 is a basic arithmetic operation. Itâ€™s simply combining one unit with one more unit. \\n\\nThe result is always two. ðŸ˜Š \\n\\nDo you want me to explain it in a more detailed way, perhaps with a step-by-step example? Or would you like me to explore some related mathematical concepts?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f8e2cd-516b-4a82-abd4-b23ae0731908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Aditya\n",
      "AI: Hello Aditya! Itâ€™s lovely to meet you. Iâ€™m glad youâ€™re here. ðŸ˜Š \n",
      "\n",
      "To help me understand a little better, could you tell me what youâ€™d like to do today?\n",
      "Human: What is 1+1?\n",
      "AI: Okay, thatâ€™s a fundamental question! 1 + 1 is a basic arithmetic operation. Itâ€™s simply combining one unit with one more unit. \n",
      "\n",
      "The result is always two. ðŸ˜Š \n",
      "\n",
      "Do you want me to explain it in a more detailed way, perhaps with a step-by-step example? Or would you like me to explore some related mathematical concepts?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thatâ€™s a very interesting question! I understand youâ€™re asking about your name. ðŸ˜Š\\n\\nI donâ€™t have access to personal information like names. Iâ€™m designed to help with various tasks and provide information, but I donâ€™t store or retain any personal details about individuals. \\n\\nPerhaps you could tell me what youâ€™d like to know about your name? Maybe youâ€™d like to know its origin, how itâ€™s spelled, or perhaps youâ€™re curious about its meaning?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a3b70a-3ec3-41a9-ac3d-8a39089495e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Aditya\n",
      "AI: Hello Aditya! Itâ€™s lovely to meet you. Iâ€™m glad youâ€™re here. ðŸ˜Š \n",
      "\n",
      "To help me understand a little better, could you tell me what youâ€™d like to do today?\n",
      "Human: What is 1+1?\n",
      "AI: Okay, thatâ€™s a fundamental question! 1 + 1 is a basic arithmetic operation. Itâ€™s simply combining one unit with one more unit. \n",
      "\n",
      "The result is always two. ðŸ˜Š \n",
      "\n",
      "Do you want me to explain it in a more detailed way, perhaps with a step-by-step example? Or would you like me to explore some related mathematical concepts?\n",
      "Human: What is my name?\n",
      "AI: Thatâ€™s a very interesting question! I understand youâ€™re asking about your name. ðŸ˜Š\n",
      "\n",
      "I donâ€™t have access to personal information like names. Iâ€™m designed to help with various tasks and provide information, but I donâ€™t store or retain any personal details about individuals. \n",
      "\n",
      "Perhaps you could tell me what youâ€™d like to know about your name? Maybe youâ€™d like to know its origin, how itâ€™s spelled, or perhaps youâ€™re curious about its meaning?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e84fde-0323-41e0-a375-70c2be39a0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi, my name is Aditya\\nAI: Hello Aditya! Itâ€™s lovely to meet you. Iâ€™m glad youâ€™re here. ðŸ˜Š \\n\\nTo help me understand a little better, could you tell me what youâ€™d like to do today?\\nHuman: What is 1+1?\\nAI: Okay, thatâ€™s a fundamental question! 1 + 1 is a basic arithmetic operation. Itâ€™s simply combining one unit with one more unit. \\n\\nThe result is always two. ðŸ˜Š \\n\\nDo you want me to explain it in a more detailed way, perhaps with a step-by-step example? Or would you like me to explore some related mathematical concepts?\\nHuman: What is my name?\\nAI: Thatâ€™s a very interesting question! I understand youâ€™re asking about your name. ðŸ˜Š\\n\\nI donâ€™t have access to personal information like names. Iâ€™m designed to help with various tasks and provide information, but I donâ€™t store or retain any personal details about individuals. \\n\\nPerhaps you could tell me what youâ€™d like to know about your name? Maybe youâ€™d like to know its origin, how itâ€™s spelled, or perhaps youâ€™re curious about its meaning?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c296e728-10c4-4271-a2f0-0b3d6adf56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d57882-c60e-428f-be1a-758f369b05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0585b075-b2c4-47dc-9ce1-534a037e4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efb01f38-b179-4038-a09d-6252e07a2a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fff7b010-b766-43d6-9a62-5c90d3639f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2508b582-0448-46b9-a96d-2b6e67f0233b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5678f-544b-40ee-a1e4-070a32caf9df",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd4f33d-d7ff-4018-96a1-5c4a92a46dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35a0df7-a882-40d1-8783-a138629047cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14520\\802562642.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71bbb40a-2ab0-4019-909a-59e4409433f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "657a76b0-5f62-4980-8ece-a133b3e695ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58fa4d32-9bfc-48a2-b3ec-c6cd32efb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c4efeb3-713d-4092-ac63-1f6827676167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is aditya\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Aditya! Itâ€™s lovely to hear from you. Iâ€™m glad you reached out. ðŸ˜Š \\n\\nTo help me understand what youâ€™re looking for, could you tell me a little bit about what youâ€™d like to know? Perhaps youâ€™re wondering about something specific, or just starting a conversation?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is aditya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19615390-37a3-4499-b033-b7bb3bd00a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is aditya\n",
      "AI: Hello Aditya! Itâ€™s lovely to hear from you. Iâ€™m glad you reached out. ðŸ˜Š \n",
      "\n",
      "To help me understand what youâ€™re looking for, could you tell me a little bit about what youâ€™d like to know? Perhaps youâ€™re wondering about something specific, or just starting a conversation?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, thatâ€™s a classic question! 1 + 1 is a fundamental mathematical operation. Itâ€™s simply combining one unit with one more unit. \\n\\nLet me tell you a little bit about it â€“ itâ€™s a foundational concept in arithmetic. Historically, itâ€™s been understood as adding one unit to one unit, resulting in two units. However, in modern mathematics, itâ€™s often defined as the sum of two individual entities.\\n\\nDo you want me to elaborate on the concept of addition itself, or perhaps discuss its significance in various contexts, like in number theory or even in everyday life?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e4d4885-1ae5-4c5d-99c2-38212b5f0f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is aditya\n",
      "AI: Hello Aditya! Itâ€™s lovely to hear from you. Iâ€™m glad you reached out. ðŸ˜Š \n",
      "\n",
      "To help me understand what youâ€™re looking for, could you tell me a little bit about what youâ€™d like to know? Perhaps youâ€™re wondering about something specific, or just starting a conversation?\n",
      "Human: What is 1+1?\n",
      "AI: Okay, thatâ€™s a classic question! 1 + 1 is a fundamental mathematical operation. Itâ€™s simply combining one unit with one more unit. \n",
      "\n",
      "Let me tell you a little bit about it â€“ itâ€™s a foundational concept in arithmetic. Historically, itâ€™s been understood as adding one unit to one unit, resulting in two units. However, in modern mathematics, itâ€™s often defined as the sum of two individual entities.\n",
      "\n",
      "Do you want me to elaborate on the concept of addition itself, or perhaps discuss its significance in various contexts, like in number theory or even in everyday life?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay! Itâ€™s Aditya. ðŸ˜Š'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2567c-242d-4b16-8e71-5f96fceabce0",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ef9680d-34e8-494d-af88-35b43c8f66da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from tiktoken) (2025.9.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c7947e5-2cdf-4017-9545-b54551f51266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = OllamaLLM(model=\"gemma3:1b\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e99e380e-8a50-4a17-a640-def83e1021e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (4.56.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\onedrive\\desktop\\pto\\langchain\\myenvi\\lib\\site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50a0e0f5-1fcc-45c4-b819-2a72f0dca25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.56.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ced50aa-5613-4698-909c-16a9839433b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14520\\941208617.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b94a7595ccb45198a4825106744a222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf20f3a20f94b60b817e880d2665df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a5f8fa2e594acb84cfa43ffbcb970a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8997eae05f1416cb35d82d73ad86179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2162e8c367144528a5260600a4c2c3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f0fdd25-b120-443e-b02a-b66acc267d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: AI is what?!\\nAI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962342fc-964a-4842-9127-96101801f5bc",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dd8b7e1-2e02-4c43-ae1b-9f2c57355c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ca30e-510f-4b89-9a91-3a9993ad2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
