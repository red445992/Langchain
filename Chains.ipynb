{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3788b5-cfc6-46f6-a90e-0930daadd7ce",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3691fb14-7458-42b4-bd1c-2f7764fab1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma3:1b http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import requests\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_= load_dotenv(find_dotenv())\n",
    "\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\")\n",
    "OLLAMA_API_URL = os.getenv(\"OLLAMA_API_URL\")\n",
    "\n",
    "print(OLLAMA_MODEL,OLLAMA_API_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfd4c60-08ac-4707-bfbe-d21d7bdbd3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt,model=OLLAMA_MODEL,temperature=0):\n",
    "    \"\"\"\n",
    "    Generates reponses from ollama LLM\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_API_URL}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\":model,\n",
    "        \"prompt\":prompt,\n",
    "        \"temperature\":temperature,\n",
    "        \"stream\":False,\n",
    "    }\n",
    "    response = requests.post(url,json=payload)\n",
    "    if response.status_code!=200:\n",
    "        raise Exception(f\"Ollama API error : {response.status_code} {response.text}\")\n",
    "    data = response.json()\n",
    "    return data['response']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83595385-8013-4f0a-a1ed-1aebe11ea9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"gemma3:1b\", temperature=0.9)\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a66dd04-21df-4559-aca7-b8de7825d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e95fbe-f888-43c1-8038-3859c75065ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15268\\1305865249.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e20648d-bfce-42b3-9445-27ec37bc852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15268\\550859008.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(product)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, let\\'s brainstorm some names for a company that makes Queen Size sheet sets. Here\\'s a breakdown of options, categorized by the vibe they evoke, with explanations of why they might work:\\n\\n**1. Emphasizing Comfort & Luxury:**\\n\\n* **Velvet Dreams:** Suggests a luxurious and dreamy experience.\\n* **The Soft Spot:**  Plays on the Queen Size size and the feeling of comfort.\\n* **Serene Sheets:** Highlights the peaceful and relaxing feeling of the sheets.\\n* **Cloud Comfort:**  Evokes a light, airy, and comfortable feeling.\\n* **Haven Sheets:** Positions the sheets as a safe and comfortable place to rest.\\n\\n**2. Highlighting the Size & Design:**\\n\\n* **Queen Size Luxe:** Straightforward and emphasizes the key product.\\n* **The Size Story:**  Suggests a focus on creating beautiful and well-designed sheets.\\n* **Pocketed Perfection:** A bit more playful, focusing on the unique aspect of Queen Size.\\n* **Round & Plush:**  Captures the key visual element of the sheets.\\n\\n**3.  Sophisticated & Elegant:**\\n\\n* **Atelier Sheets:** \"Atelier\" means workshop or studio, implying craftsmanship and quality.\\n* **The Linen Collective:**  (If they use linen) – Feels upscale and a little bit timeless.\\n* **Aurum Sheets:** (Aurum is Latin for gold) – Adds a touch of luxury and value.\\n* **Legacy Textiles:** Suggests quality and enduring style.\\n\\n**4.  Playful & Unique (depending on branding):**\\n\\n* **The Cozy Corner:** Friendly and inviting.\\n* **Sheetful of Bliss:** A bit whimsical and emphasizes happiness.\\n* **Restful Threads:**  Simple and memorable.\\n\\n\\n**My Top Recommendations (balancing appeal and memorability):**\\n\\n*   **Velvet Dreams:**  It’s evocative, memorable, and clearly communicates the product.\\n*   **Queen Size Luxe:**  Direct, descriptive, and easily understood.\\n*   **The Soft Spot:** Short, catchy, and speaks to the comfort aspect.\\n\\n**To help me narrow it down and give you even better suggestions, could you tell me:**\\n\\n*   **What is the overall brand aesthetic you’re going for?** (e.g., luxurious, cozy, modern, traditional, bohemian?)\\n*   **What is the company’s unique selling proposition (USP)?** (e.g., linen only, eco-friendly materials, special designs?)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e285dc-b8d5-4633-9629-8e51a7332266",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f88cca-1cc2-4eb4-9e77-4ae140eb48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83091843-6244-4b01-a3ad-ec7b0ba87328",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"gemma3:1b\", temperature=0.9)\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dfbd4dc-69eb-4b72-a7f0-dd838eceeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65695711-81ec-4295-ac92-7b6ebf781fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2568c274-04d2-4440-9ed5-abf4e6af1558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mOkay, let's brainstorm some names for a company that makes Queen Size Sheet Sets. Here's a breakdown of ideas, categorized by the feeling they evoke, along with a little explanation of why they might work:\n",
      "\n",
      "**1. Classic & Comfort Focused:**\n",
      "\n",
      "*   **The Cozy Comforts:** Simple, highlights the feeling of the sheets.\n",
      "*   **Soft Embrace Textiles:** Emphasizes the softness and comfort.\n",
      "*   **Serene Sleep Solutions:** Appeals to the desire for a restful night's sleep.\n",
      "*   **The Comfort Weaver:**  A bit more evocative and suggests skilled craftsmanship.\n",
      "\n",
      "**2. Playful & Evocative:**\n",
      "\n",
      "*   **Royal Rest:**  Combines the Queen Size name with the benefit of rest.\n",
      "*   **The Velvet Dream:**  Uses a luxurious material and a dreamy feeling.\n",
      "*   **Slumberly:** A cute and memorable name.\n",
      "*   **Twilight Threads:**  Connects to the nighttime and the soft texture.\n",
      "\n",
      "**3. Modern & Stylish:**\n",
      "\n",
      "*   **The Linen Standard:**  Focuses on the quality of the fabric (linen).\n",
      "*   **Ember Sleep:** Suggests warmth and comfort.\n",
      "*   **Hue & Hush:** (If they have a focus on color and quiet sleep)\n",
      "*   **Nest Bed:** Implies a comfortable and cozy bedroom.\n",
      "\n",
      "**4. Unique & Creative:**\n",
      "\n",
      "*   **The Silken Touch:**  Highlights the luxurious feel.\n",
      "*   **Whisper Weave:** A more poetic name, focusing on the softness.\n",
      "*   **Velvet Bloom:** A slightly more artistic name.\n",
      "\n",
      "**5. Short & Memorable:**\n",
      "\n",
      "*   **Queen Luxe** - Simple and clearly communicates the product.\n",
      "*   **Restful Threads** - Short and impactful.\n",
      "\n",
      "\n",
      "**My Top 3 Recommendations (Based on overall appeal and brand potential):**\n",
      "\n",
      "1.  **The Cozy Comforts:**  Easy to understand and conveys the core benefit.\n",
      "2.  **Royal Rest:**  A catchy and memorable name.\n",
      "3.  **Velvet Dream:**  Evokes a luxurious and pleasant experience.\n",
      "\n",
      "**To help me narrow it down further and suggest the *absolute best* name, could you tell me:**\n",
      "\n",
      "*   **What is the overall brand aesthetic/personality of the company?** (e.g., luxury, affordable, vintage-inspired, modern, bohemian)\n",
      "*   **What is the company's target audience?** (e.g., affluent homeowners, young professionals, seniors?)\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mOkay, great! Let’s refine the recommendations based on your feedback.\n",
      "\n",
      "**Here’s my updated response, incorporating your feedback:**\n",
      "\n",
      "**Overall, the company is aiming for a luxurious, comfortable, and subtly stylish brand. Think high-quality, beautiful, and a little bit indulgent. The target audience is likely affluent homeowners or individuals who prioritize comfort and relaxation.**\n",
      "\n",
      "**Based on your Top 3 recommendations, and considering the brand aesthetic, here’s a revised list of recommendations, with a bit more explanation:**\n",
      "\n",
      "1.  **The Cozy Comforts:** (Still excellent - core benefit, easy to understand) – **Rationale:** It’s instantly relatable and speaks to the primary benefit of the product.\n",
      "\n",
      "2.  **Royal Rest:** (Excellent - catchy, memorable, and emphasizes the desired outcome) – **Rationale:**  It’s a strong, aspirational name that conveys a sense of luxury and tranquility.  It’s also memorable.\n",
      "\n",
      "3.  **Velvet Dream:** (Strong - Evokes a luxurious, soft, and pleasant experience) – **Rationale:**  It's a beautiful and evocative name that strongly suggests the quality of the sheets.\n",
      "\n",
      "**Now, to help me narrow things down further, could you tell me:**\n",
      "\n",
      "*   **What is the company’s primary color palette or style?** (e.g., muted tones, bold colors, minimalist, floral, etc.)\n",
      "*   **Is there a specific *feeling* you want the name to evoke beyond comfort and relaxation?** (e.g., nostalgia, elegance, warmth, sophistication?)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, great! Let’s refine the recommendations based on your feedback.\\n\\n**Here’s my updated response, incorporating your feedback:**\\n\\n**Overall, the company is aiming for a luxurious, comfortable, and subtly stylish brand. Think high-quality, beautiful, and a little bit indulgent. The target audience is likely affluent homeowners or individuals who prioritize comfort and relaxation.**\\n\\n**Based on your Top 3 recommendations, and considering the brand aesthetic, here’s a revised list of recommendations, with a bit more explanation:**\\n\\n1.  **The Cozy Comforts:** (Still excellent - core benefit, easy to understand) – **Rationale:** It’s instantly relatable and speaks to the primary benefit of the product.\\n\\n2.  **Royal Rest:** (Excellent - catchy, memorable, and emphasizes the desired outcome) – **Rationale:**  It’s a strong, aspirational name that conveys a sense of luxury and tranquility.  It’s also memorable.\\n\\n3.  **Velvet Dream:** (Strong - Evokes a luxurious, soft, and pleasant experience) – **Rationale:**  It's a beautiful and evocative name that strongly suggests the quality of the sheets.\\n\\n**Now, to help me narrow things down further, could you tell me:**\\n\\n*   **What is the company’s primary color palette or style?** (e.g., muted tones, bold colors, minimalist, floral, etc.)\\n*   **Is there a specific *feeling* you want the name to evoke beyond comfort and relaxation?** (e.g., nostalgia, elegance, warmth, sophistication?)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b77b8-7189-4ded-8eb7-19f4af1aefb1",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d0ba92f-b39e-474f-b857-da7045a6c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34c9d8a6-51a5-4f78-a735-4827507fd360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95857a98-44d7-43d2-b141-4daa6ac5d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc5f0389-6bdb-4dd8-a2cc-14976d7a8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf8633f6-0d77-4e21-960a-e6b31b778f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bfe9835-7c21-49b8-b39b-4ddb49f913c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0ca4444-2b90-4194-9076-d036357e62dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15268\\3804859531.py:14: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_chain(review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': 'For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\n',\n",
       " 'English_Review': 'Please provide the text you would like me to translate into English. I need the text of the review to perform the requested extraction. 😊\\n',\n",
       " 'summary': 'Please paste the review text you’d like me to translate! 😊\\n',\n",
       " 'followup_message': 'Okay, here’s the review text:\\n\\n“Honestly, this coffee shop is a total disaster. The latte art was atrocious – like, completely misshapen blobs. And the barista seemed completely disinterested, barely making eye contact. The atmosphere was also incredibly loud – I couldn’t even have a conversation! Seriously, I wouldn’t recommend going here. It was a really awful experience.”\\n\\nNow, please translate this review into Spanish. 😊\\n'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review =  \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "\"\"\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d920883a-e6b9-4568-9473-1f452d0bbb2f",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eb6077d-2604-4536-9a16-47ef8ebe341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02702c0a-f20b-4957-93a5-47638a3a1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db490706-b249-4cd0-ab54-27166e505738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67a77f43-db14-44df-8928-d6ea56c0ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00318bb9-9162-4daa-b3d4-dbee0dcb2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d6e771b-732f-44fa-b2c0-ba258e0cce55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15268\\3710404048.py:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n"
     ]
    }
   ],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ \"DEFAULT\" or name of the prompt to use in {destinations}\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: The value of “destination” MUST match one of \\\n",
    "the candidate prompts listed below.\\\n",
    "If “destination” does not fit any of the specified prompts, set it to “DEFAULT.”\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5789b272-6246-4d51-b9f8-ab58390ea7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "922fd1da-4c2d-48d8-97fa-d2eb4af7e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15268\\3038952769.py:1: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6485d52f-229c-4e17-b18b-988ce55a62a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Alright, let’s tackle black body radiation.\\n\\nSimply put, **black body radiation is the electromagnetic radiation emitted by an object when it’s heated.**  \\n\\nHere’s a breakdown of why it’s important:\\n\\n*   **It's a fundamental process:**  Everything that emits radiation – even perfect, still objects – does so.\\n*   **It’s all about wavelength and frequency:**  The *color* of light emitted isn’t determined by the color itself; it's determined by the object's temperature.\\n*   **The Stefan-Boltzmann Law:** This law describes how much energy a black body emits per unit area per unit time.  It’s a cornerstone of understanding this phenomenon.\\n\\n**Essentially, it's the 'heat glow' of an object.**\\n\\nDo you want me to delve into a specific aspect, like the relationship to temperature, or perhaps how it’s used in astrophysics?\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f960638a-7ae1-4ad1-adbd-f560f3239bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'That’s a fundamental question! 2 + 2 equals 4. \\n\\nIt’s a basic arithmetic operation. 😊 \\n\\nDo you have any other questions?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d53051f2-53f1-4f8b-8495-1e4da24937d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, that’s a fantastic question! It’s a really important one, and the answer is surprisingly elegant.\\n\\nEvery cell in your body contains DNA – deoxyribonucleic acid – because it’s the fundamental blueprint for *everything* you are.  Here’s the breakdown:\\n\\n*   **DNA is the Genetic Code:** DNA’s primary function is to store and transmit genetic information. Think of it like a really long instruction manual for building and operating a living thing.\\n\\n*   **Inheritance:**  Our genes – the instructions in DNA – are passed down from parents to offspring.  Without DNA, there would be no continuity of traits.\\n\\n*   **Cellular Differentiation:**  Each cell in your body has a unique set of DNA. This is crucial for different cell types to perform specialized functions – a muscle cell, a nerve cell, a skin cell – all have their own unique DNA.\\n\\nSo, DNA is absolutely essential for the survival and function of *every* cell. It’s the key to life as we know it!\\n\\n---\\n\\nDo you have any other physics questions you’d like me to tackle?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56501b1f-713b-49eb-8afd-381882306aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
